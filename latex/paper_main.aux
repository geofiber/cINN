\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{pnas-new}
\citation{zappia2017splatter,beaumont2002approximate}
\citation{palestro2018likelihood,usher2001time}
\citation{hwang2018conditional,lueckmann2017flexible}
\citation{wood2010statistical}
\citation{hethcote2000mathematics}
\citation{palestro2018likelihood,csillery2010approximate,toni2009simulation}
\babel@aux{english}{}
\newlabel{eqn:1}{{{1}}{1}{}{AMS.2}{}}
\zref@newlabel{mdf@pagelabel-1}{\default{\caption@xref {??}{ on input line 54}}\page{1}\abspage{1}\mdf@pagevalue{1}}
\pgfsyspdfmark {pgfid1}{3411189}{6943896}
\citation{palestro2018likelihood,turner2014generalized}
\citation{turner2014generalized,sunnaaker2013approximate,csillery2010approximate}
\citation{csillery2010approximate,mertens2018abrox}
\citation{frazier2018asymptotic,palestro2018likelihood}
\citation{radev2019towards,hwang2018conditional,mestdagh2018prepaid,raynal2018abc,jiang2017learning,lueckmann2017flexible,papamakarios2016fast}
\citation{ardizzone2018analyzing,kingma2018glow,grover2018flow,dinh2016density}
\citation{bloem2019probabilistic}
\citation{goodfellow2016deep}
\citation{kingma2018glow,grover2018flow,dinh2016density}
\citation{kendall2017uncertainties,gelman2013bayesian}
\citation{mestdagh2018prepaid}
\citation{abadi2016tensorflow}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A graphic illustration of the two phases of the method. \textbf  {(a)} During the training phase, the networks are trained on simulated data from the model; \textbf  {(b)} during the inference phase, the posterior is approximated from real data.\relax }}{3}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:first}{{1}{3}{A graphic illustration of the two phases of the method. \textbf {(a)} During the training phase, the networks are trained on simulated data from the model; \textbf {(b)} during the inference phase, the posterior is approximated from real data.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training phase}}}{3}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Inference phase}}}{3}{subfigure.1.2}\protected@file@percent }
\citation{bloem2019probabilistic,kingma2018glow,ardizzone2018analyzing,kingma2014auto}
\citation{ardizzone2018analyzing}
\citation{ardizzone2018analyzing,kingma2018glow,dinh2016density}
\newlabel{eqn:2}{{{2}}{4}{}{AMS.6}{}}
\newlabel{eqn:3}{{{3}}{4}{}{AMS.7}{}}
\newlabel{eqn:4}{{{4}}{4}{}{AMS.10}{}}
\newlabel{eqn:5}{{{5}}{4}{}{AMS.11}{}}
\newlabel{eqn:6}{{{6}}{4}{}{AMS.13}{}}
\newlabel{eqn:7}{{{7}}{4}{}{AMS.15}{}}
\citation{papamakarios2016fast,kingma2014auto}
\newlabel{eqn:8}{{{8}}{5}{}{AMS.17}{}}
\newlabel{eqn:9}{{{9}}{5}{}{AMS.19}{}}
\newlabel{eqn:10}{{{10}}{5}{}{AMS.22}{}}
\newlabel{eqn:11}{{{11}}{5}{}{AMS.23}{}}
\newlabel{eqn:12}{{{12}}{5}{}{AMS.27}{}}
\newlabel{eqn:13}{{{13}}{5}{}{AMS.28}{}}
\newlabel{eqn:14}{{{14}}{5}{}{AMS.29}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Bayesian likelihood-free inference with invertible neural networks\relax }}{6}{algorithm.1}\protected@file@percent }
\newlabel{Algorithm:algo}{{1}{6}{Bayesian likelihood-free inference with invertible neural networks\relax }{algorithm.1}{}}
\citation{kendall2017uncertainties,gelman2013bayesian}
\citation{radev2019towards,hwang2018conditional,mestdagh2018prepaid,raynal2018abc,jiang2017learning,lueckmann2017flexible,papamakarios2016fast}
\citation{papamakarios2016fast,kingma2014auto}
\citation{kingma2018glow,dinh2016density}
\citation{radev2019towards,raynal2018abc}
\citation{mestdagh2018prepaid}
\bibdata{references}
\bibcite{zappia2017splatter}{{1}{}{{}}{{}}}
\bibcite{beaumont2002approximate}{{2}{}{{}}{{}}}
\bibcite{palestro2018likelihood}{{3}{}{{}}{{}}}
\bibcite{usher2001time}{{4}{}{{}}{{}}}
\bibcite{hwang2018conditional}{{5}{}{{}}{{}}}
\bibcite{lueckmann2017flexible}{{6}{}{{}}{{}}}
\bibcite{wood2010statistical}{{7}{}{{}}{{}}}
\bibcite{hethcote2000mathematics}{{8}{}{{}}{{}}}
\bibcite{csillery2010approximate}{{9}{}{{}}{{}}}
\bibcite{toni2009simulation}{{10}{}{{}}{{}}}
\bibcite{turner2014generalized}{{11}{}{{}}{{}}}
\bibcite{sunnaaker2013approximate}{{12}{}{{}}{{}}}
\bibcite{mertens2018abrox}{{13}{}{{}}{{}}}
\bibcite{frazier2018asymptotic}{{14}{}{{}}{{}}}
\bibcite{radev2019towards}{{15}{}{{}}{{}}}
\bibcite{mestdagh2018prepaid}{{16}{}{{}}{{}}}
\bibcite{raynal2018abc}{{17}{}{{}}{{}}}
\bibcite{jiang2017learning}{{18}{}{{}}{{}}}
\bibcite{papamakarios2016fast}{{19}{}{{}}{{}}}
\bibcite{ardizzone2018analyzing}{{20}{}{{}}{{}}}
\bibcite{kingma2018glow}{{21}{}{{}}{{}}}
\bibcite{grover2018flow}{{22}{}{{}}{{}}}
\bibcite{dinh2016density}{{23}{}{{}}{{}}}
\bibcite{bloem2019probabilistic}{{24}{}{{}}{{}}}
\bibcite{goodfellow2016deep}{{25}{}{{}}{{}}}
\bibcite{kendall2017uncertainties}{{26}{}{{}}{{}}}
\bibcite{gelman2013bayesian}{{27}{}{{}}{{}}}
\bibcite{abadi2016tensorflow}{{28}{}{{}}{{}}}
\bibcite{kingma2014auto}{{29}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{LastPage}{{}{8}{}{page.8}{}}
\xdef\lastpage@lastpage{8}
\xdef\lastpage@lastpageHy{8}
