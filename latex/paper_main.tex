\documentclass[9pt,twoside,lineno]{pnas-new}
% Use the lineno option to display guide line numbers if required.

\templatetype{pnasmathematics} % Choose template 
% {pnasresearcharticle} = Template for a two-column research article
% {pnasmathematics} = Template for a one-column mathematics article

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{subcaption} 
\usepackage{cleveref}
\graphicspath{{figures/}}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\title{Learning complex stochastic models with invertible neural networks: a likelihood-free Bayesian approach}

% Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
\author[1]{Stefan T. Radev}
\author[1]{Ulf K. Mertens} 
\author[1]{Andreas Voss}
\author[2]{Lynton Ardizzone}
\author[2]{Ullrich Köthe}

\affil[1]{Institute of Psychology, Heidelberg University, Hauptstr. 47-51, 69117 Heidelberg, Germany}
\affil[2]{Heidelberg Collaboratory for Image Processing (HCI), Interdisciplinary Center for Scientific Computing (IWR), Heidelberg University, Im Neuenheimer Feld 205, 69120 Heidelberg, Germany}

% Please give the surname of the lead author for the running footer
\leadauthor{Radev} 

% Please add here a significance statement to explain the relevance of your work
\significancestatement{Describing complex stochastic processes with parametric  models lies at the heart of science. Simulating models given a set of parameters is relatively easy with the aid of modern computers, but inferring model parameters from observed data can often be a challenging endeavor. We combine recent advances in deep learning and Bayesian inference into a powerful method for building reusable parameter estimation networks applicable to various types of models and data encountered in different research fields.}

% Please include corresponding author, author contribution and author declaration information
\authorcontributions{Please provide details of author contributions here.}
\authordeclaration{This research was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation; grant number GRK 2277 "Statistical Modeling in Psychology")}


\correspondingauthor{\textsuperscript{2}To whom correspondence should be addressed. E-mail: stefan.radev@psychologie.uni-heidelberg.de}

% At least three keywords are required at submission. Please provide two to five keywords, separated by the pipe symbol.
\keywords{Deep learning $|$ Invertible networks $|$ Bayesian inference $|$ Parameter estimation $|$ Stochastic models} 

\begin{abstract}
Mathematical models of complex processes are ubiquitous throughout the sciences. As the processes under study and the models describing them become increasingly complex, parameter estimation with standard Bayesian and frequentist methods can quickly become intractable. To address this issue, we propose a novel method for likelihood-free inference based on invertible neural networks. The method is capable of performing full Bayesian inference on large datasets by training the networks on simulated data to learn a probabilistic mapping between parameters and data. The method is independent of any particular data representation, as it incorporates a summary network trained to embed the observed data into fixed-size vectors in a data-driven way. This makes the method applicable to various scenarios where standard inference techniques fail. We demonstrate the utility of the method on a toy model with known analytic posterior and on example models from population dynamics, epidemiology, cognitive science and genetics. We argue that our method provides a general framework for building reusable parameter estimation machines for any process model from which data can be simulated.
\end{abstract}

\dates{This manuscript was compiled on \today}
\doi{\url{www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX}}

\begin{document}

\maketitle
\thispagestyle{firststyle}
\ifthenelse{\boolean{shortarticle}}{\ifthenelse{\boolean{singlecolumn}}{\abscontentformatted}{\abscontent}}{}

\dropcap{M}athematical models are formal descriptions of scientific theories. In its most abstract form, a mathematical model is specified by a set of parameters $\boldsymbol{\theta}$ and a forward model $q$ mimicking the process by which manifest data $\boldsymbol{x}$ arise from latent parameters: 
\begin{align*}
\boldsymbol{x}= q(\boldsymbol{\theta}) \numberthis \label{eqn:1} 
\end{align*}
The functional form of $q$, which can represent an arbitrarily complex process by an arbitrarily complicated expression, is usually guided by a well-founded theoretical framework. For instance, $q$ can be a stochastic differential equation describing the dynamics of single neurons in the brain, or a step-by-step biological algorithm controlling the rate of gene expression in certain cells. Thus, it is only within the context of a theory that a meaningful interpretation in terms of some mechanism can be attached to the parameters of a mathematical model. Examples of mathematical models can be found in various scientific domains, for instance, genetics \cite{zappia2017splatter, beaumont2002approximate}, cognitive science \cite{palestro2018likelihood, usher2001time}, neuroscience \cite{hwang2018conditional, lueckmann2017flexible}, population dynamics \cite{wood2010statistical, geritz2004mechanistic}, epidemiology \cite{keeling2011modeling,hethcote2000mathematics}, to name just a few.

An important goal of mathematical modeling is recovering parameters of the model from observed data. Idealized parameter estimation involves computing the inverse (backward) model $\boldsymbol{\theta} = q^{-1}(\boldsymbol{x})$ exactly. Unfortunately, this inverse rarely exists, and estimating parameters remains computationally inconvenient in a wide range of settings. 

Parameter estimation becomes notably difficult when the forward model in Eq.\ref{eqn:1} does not provide a closed-form for the \textit{likelihood function} \cite{palestro2018likelihood, csillery2010approximate, toni2009simulation}. This poses great difficulties for Bayesian and frequentist methods alike, since both depend on the numerical evaluation of a likelihood function as a proxy for assessing model fit to data. Even if a likelihood function is available in closed-form, inference may be prohibitively slow for real-world applications. In this case, enforcing simplifying distributional assumptions (i.e., independence or Gaussian assumptions) can increase computational speed, but can also lead to model misspecifications and dramatically incorrect estimates. Therefore, there is a need for accurate and computationally convenient likelihood-free estimation methods.

Likelihood-free methods bypass the above problems by resorting to a simulation-based approach to parameter estimation and model selection \cite{palestro2018likelihood, turner2014generalized}. A subset of likelihood-free methods includes approximate Bayesian computation (ABC) methods, which aim at preserving the advantages of Bayesian data analysis even when the likelihood function is intractable or practically impossible to compute \cite{turner2014generalized, sunnaaker2013approximate, csillery2010approximate}. ABC methods approximate the likelihood function by repeatedly sampling parameters from a pre-specified prior distribution $p(\boldsymbol{\theta})$ and then simulating multiple datasets by running the forward model $q(\boldsymbol{\theta})$ using the sampled parameters. Correspondingly, the core ingredients of ABC methods are a prior on $\boldsymbol{\theta}$, and a generative model $q(\boldsymbol{\theta})$, usually specified as a function code in a general-purpose programming language \cite{csillery2010approximate, mertens2018abrox}.

Performing approximate inference comes at the cost of incurring additional approximation error, which accumulates on top of the irreducible estimation error. Within the context of approximate inference, the most common manifestations of approximation error include: \textit{i)} imprecise form of the posterior; \textit{ii)} imprecise posterior moments; \textit{iii)} under- or overestimation of uncertainty. Different approximation methods usually involve multiple trade-offs between minimizing approximation error and keeping computational time within reasonable bounds \cite{frazier2018asymptotic, palestro2018likelihood}.

To address the shortcomings of traditional methods, ideas from machine learning and deep learning research have recently entered the field of likelihood-free inference \cite{mertens2019deep, radev2019towards, hwang2018conditional, mestdagh2018prepaid, raynal2018abc, jiang2017learning, lueckmann2017flexible, papamakarios2016fast}. The most common approach has been to cast the problem of parameter estimation as a supervised learning task. In this setting, a large dataset of the form $\boldsymbol{D} = \{h(\boldsymbol{x}^{(i)}), \boldsymbol{\theta}^{(i)}\}_{i=1}^{n}$ is created by repeatedly sampling from $p(\boldsymbol{\theta})$ and simulating an artificial dataset $\boldsymbol{x}$ by running $q(\boldsymbol{\theta})$ with the sampled parameters. Usually, the dimensionality of the simulated data is reduced by computing summary statistics  with a fixed summary function $h(\boldsymbol{x})$. Then, a supervised learning algorithm $f(h(\boldsymbol{x});\boldsymbol{\phi}) = \widehat{\boldsymbol{\theta}}$ with learnable parameters $\boldsymbol{\phi}$ (e.g., linear regression, random forest, neural network) is trained on the simulated data to output an estimate of the true data generating parameters. Thus, $f(h(\boldsymbol{x});\boldsymbol{\phi})$ essentially attempts to “learn” the intractable inverse model $\boldsymbol{\theta} = q^{-1}(\boldsymbol{x})$.

Inspired by previous machine learning approaches \cite{hwang2018conditional, mestdagh2018prepaid, raynal2018abc, jiang2017learning, lueckmann2017flexible, papamakarios2016fast}, the current work proposes a novel and universal likelihood-free method capable of performing full Bayesian inference on any mathematical process model from which simulations can be obtained. It treats parameter inference as a task of inverting the forward model in Eq.\ref{eqn:1} and achieves this by drawing on the modern framework of deep probabilistic modeling for tackling intractable posteriors \cite{ardizzone2018analyzing, kingma2018glow, grover2018flow, dinh2016density}. The method integrates two separate deep neural networks modules (detailed in the \textbf{Methods} section; see \autoref{fig:Fig.1}) trained jointly on simulated data: a \textit{summary network} and an \textit{invertible network}. 

The \textit{summary network} is responsible for learning the most informative summary statistics directly from data. It should be designed to follow the functional and probabilistic symmetries inherent in the data, e.g. an invariant network for \textit{i.i.d.} data \cite{bloem2019probabilistic}, a recurrent network \cite{gers1999learning} or a convolutional network \cite{long2015fully} for data with temporal or spatial dependencies. Ideally, it should also be independent of the number of observations. The computation of summary statistics is a crucial aspect in likelihood-free inference. Previous approaches typically used hand-crafted summary statistics tailored to the specific application \cite{raynal2018abc, sunnaaker2013approximate}. However, in many applications, finding an optimal set of summary statistics is far from obvious. The summary network eliminates the need to manually decide on and compute a fixed set of summary statistics and, thus, makes the method independent of the format or the size of the data.

The \textit{invertible network} is responsible for learning the posterior of the model parameters given the observed and summarized data. It is based on the recently developed flow-based architecture \cite{kingma2018glow, grover2018flow, dinh2016density}. Flow-based methods provide exact latent-variable inference and log-likelihood evaluation when operating at optimum. In the \textbf{Methods} section, we show that our method maximizes the posterior over model parameters directly when cast in the context of likelihood-free inference. Furthermore, flow-based methods are capable of approximating high-dimensional distributions (e.g., the pixels of an image). Once trained with a sufficient amount of simulated data, the invertible network can perform rapid Bayesian inference on large datasets from a given research domain. 
\begin{figure}
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{training.png}
    \caption{Training phase}
    \label{fig:Fig.1a}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{inference.png}
    \caption{Inference phase}
    \label{fig:Fig.1b}
  \end{subfigure}
      \caption{Graphical illustration of the method. \textbf{(a)} During the training phase, the summary and the invertible network are trained on simulated data from the model and updated after each batch of simulations; \textbf{(b)} During the inference phase, the true posterior of the model parameters is approximated from real data using the trained networks. Thus, knowledge about the relationship between parameters and data (the mathematical model) is compactly encoded within the weights of the two networks. The trained networks can then be shared and used across researchers working on the same model.} \label{fig:Fig.1}
\end{figure}

The joint training of a summary network and an invertible network results in a powerful and universal parameter estimation machine capable of estimating complex mathematical models in various scientific domains (\autoref{fig:Fig.1}). Moreover, the method addresses many of the limitations of previous likelihood-free methods. First, it involves no costly MCMC or rejection sampling, which makes inference lightning fast, once the networks have been trained. Second, it involves no fixed summary statistics, but instead learns the most informative representation of the data in an end-to-end manner. Third, the method is fully Bayesian, as it directly learns the posterior over model parameters and thus allows for the quantification of uncertainty, which is a crucial requirement in parameter estimation \cite{kendall2017uncertainties, gelman2013bayesian}. Last, the trained networks can be shared and reused by multiple researches within a scientific domain, thus removing the need for wasteful computations and fitting a separate model for each and every dataset. This pooling of computational resources across researchers is an important step forward in mathematical modeling \cite{mestdagh2018prepaid}.

To illustrate the utility of the new method, we first apply it to a toy Bayesian regression model with known posterior. Then, we present applications to intractable models from cognitive science, population dynamics, epidemiology, and genetics and demonstrate state-of-the art parameter recovery. Across the examples, we introduce multiple tools to validate the performance of our method. The outline of the remaining manuscript is as follows: The \textbf{Methods} section introduces the main building blocks of the new method and summarizes the main steps in pseudocode. The \textbf{Results} section presents the various applications of the model to real-world research domains. Finally, the \textbf{Discussion} section lists the advantages of the current method, treats some potential pitfalls and explores future research vistas. Python code and simulation scripts for all current applications are freely available as Jupyter notebooks at \href{https://github.com/stefanradev93/cINN}{https://github.com/stefanradev93/cINN} and as a small library based on \textit{TensorFlow} \cite{abadi2016tensorflow} for creating and training custom invertible networks with GPU support, along with some validation tools. 

\section*{Methods}

\subsection*{Notation}

In the following, we denote observed or simulated univariate datasets from the mathematical model of interest as $\boldsymbol{x} = (x_{1}, x_{2},...,x_{n})$, and multivariate datasets as $\boldsymbol{X} = (\boldsymbol{x}_{1}, \boldsymbol{x}_{1},...,\boldsymbol{x}_{n})$. The parameters of a mathematical model are represented as a vector $\boldsymbol{\theta} = (\theta_{1}, \theta_{2},...,\theta_{d})$, and all trainable parameters of the invertible and summary neural networks as $\boldsymbol{\phi} = (\boldsymbol{\phi}_{inv}, \boldsymbol{\phi}_{sum})$. The number of parameters of a mathematical model will be denoted as $d$, and the number of observations in $\boldsymbol{x}$ or $\boldsymbol{X}$ as $n$.

\subsection*{Deep Probabilistic Modeling}

Our method draws on major advances in modern deep probabilistic modeling, also referred to as deep generative modeling \cite{bloem2019probabilistic, kingma2018glow, ardizzone2018analyzing, kingma2014auto}. A hallmark idea in deep probabilistic modeling is to handle intractable target probability distributions by sampling from simpler distributions (e.g., Gaussian or uniform distributions) and transforming these samples via learned complex non-linear transformations. Most popular deep probabilistic models entail two phases. During the \textit{training phase}, a transformation from the simple to the desired target distribution is learned by optimizing a cost function via backpropagation (see \autoref{fig:Fig.1a}). During the \textit{inference phase}, samples from the target distribution are obtained by sampling from the simple distribution and applying the transformation learned during the training phase (see \autoref{fig:Fig.1b}). Using this approach, recent applications of deep probabilistic models have achieved unprecedented results on extremely high-dimensional and intractable problems (e.g., complex data distributions such as images, music, or text)  \cite{bloem2019probabilistic, kingma2018glow, grover2018flow}.

In the context of mathematical modeling and Bayesian inference, the target distribution is the posterior distribution of model parameters $p(\boldsymbol{\theta}|\boldsymbol{x})$ capturing the uncertainty about the numerical values of parameters. We can leverage the fact that most mathematical models are generative in nature and as such can be used to perform multiple simulations of the process of interest. By specifying a prior distribution over the model parameters $p(\boldsymbol{\theta})$, one can generate arbitrarily large datasets of the form $\boldsymbol{D} = \{\boldsymbol{x}^{(i)}, \boldsymbol{\theta}^{(i)}\}_{i=1}^{n}$ and use a deep generative model to learn a probabilistic mapping from data to parameters. Thus, during the inference phase, the model generates samples $\boldsymbol{\theta}^{(1)}, \boldsymbol{\theta}^{(2)},...,\boldsymbol{\theta}^{(L)}$ from the observed data $\boldsymbol{x}_{obs}$, approximating the target posterior $p(\boldsymbol{\theta}|\boldsymbol{x}=\boldsymbol{x}_{obs})$.

In the current work, we propose to implement and use a conditional invertible neural network (cINN) architecture. Previously, INNs have been successfully employed to model data from astrophysics and medicine\cite{ardizzone2018analyzing}. We adapt the model to suit the task of parameter estimation in the context of mathematical modeling (see Figure 1 for a full graphical illustration of the method) and develop a reusable probabilistic architecture for full Bayesian likelihood-free inference on complex mathematical models.

\subsection*{The Affine Coupling Block}

The basic building block of a cINN is the affine coupling block (ACB, see \autoref{fig:Fig.2a}) \cite{ardizzone2018analyzing, kingma2018glow, dinh2016density}. Each cACB consists of four separate fully connected neural networks denoted as $s_{1}(\cdot), s_{2}(\cdot), t_{1}(\cdot), t_{2}(\cdot)$. An ACB is specifically designed to be invertible, which means that in addition to a parametric mapping $f_{\boldsymbol{\phi}_{inv}}: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d}$ it also learns the inverse mapping $f_{\boldsymbol{\phi}_{inv}}^{-1}: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d}$ "for free". Denoting the input vector of $f_{\boldsymbol{\phi}_{inv}}$ as $\boldsymbol{u}$ and the output vector as $\boldsymbol{v}$, it follows that $f(\boldsymbol{u}; \boldsymbol{\phi}_{inv}) = \boldsymbol{v}$ and $f^{-1}(\boldsymbol{v}; \boldsymbol{\phi}_{inv}) = \boldsymbol{u}$. Invertibility is achieved by splitting the input vector into two parts $\boldsymbol{u} = (\boldsymbol{u}_{1}, \boldsymbol{u}_{2})$ and performing the following operations on the split input:
\begin{align*} 
\boldsymbol{v}_{1} &= \boldsymbol{u}_{1} \odot \exp(s_{1}(\boldsymbol{u}_{2})) + t_{1}(\boldsymbol{u}_{2}) \numberthis \label{eqn:2}  \\ 
\boldsymbol{v}_{2} &= \boldsymbol{u}_{2} \odot \exp(s_{1}(\boldsymbol{v}_{1})) + t_{1}(\boldsymbol{v}_{1}) \numberthis \label{eqn:3} 
\end{align*}
The outputs $\boldsymbol{v} = (\boldsymbol{v}_{1}, \boldsymbol{v}_{2})$ are then concatenated again and passed to the next ACB. The inverse operation is given by:
\begin{align*} 
\boldsymbol{u}_{2} &= (\boldsymbol{v}_{2} - t_{2}(\boldsymbol{v}_{1})) \odot \exp(-s_{2}(\boldsymbol{v}_{1})) \numberthis \label{eqn:4}  \\ 
\boldsymbol{u}_{1} &= (\boldsymbol{v}_{1} - t_{1}(\boldsymbol{u}_{2})) \odot \exp(-s_{1}(\boldsymbol{u}_{2})) \numberthis \label{eqn:5} 
\end{align*}
An additional property of this design, which becomes relevant later for optimization, is that the operations of the ACB have tractable, and cheaply computable Jacobians (strictly upper or lower triangular matrices). Furthermore, the internal networks $s_{1}(\cdot), s_{2}(\cdot), t_{1}(\cdot), t_{2}(\cdot)$ can be represented by arbitrarily complex neural networks, which themselves need not be invertible, since they are only ever evaluated in the forward direction during both the forward and the inverse pass through the ACB. To ensure that the model is powerful enough to represent complicated distributions, we chain multiple ACBs, so that the output of each ACB becomes the input of the next (see \autoref{fig:Fig.2b}). In this way, the whole chain remains invertible from the first input to the last output and can be viewed as a single function parameterized by trainable parameters $\boldsymbol{\phi}_{inv}$.

In our applications, the input to the first ACB is the parameter vector $\boldsymbol{\theta}$, and the output of the final ACB, denoted hitherto as $\boldsymbol{z}$, is encouraged to follow a $d$-dimensional spherical Gaussian via optimization (described in detail later), that is, $p(\boldsymbol{z}) = \mathcal{N}_{d}(\boldsymbol{z}|\boldsymbol{0},\boldsymbol{I})$. Fixed permutation matrices are used before each ACB to ensure that each axis of the latent space encodes information from all components of $\boldsymbol{\theta}$. In order to take into account the observed or simulated data $\boldsymbol{x}$, each of the internal networks of each ACB is augmented to take $\boldsymbol{x}$ as an additional input - $s_{1}(\cdot,\boldsymbol{x}), s_{2}(\cdot,\boldsymbol{x}), t_{1}(\cdot,\boldsymbol{x}), t_{2}(\cdot,\boldsymbol{x})$ - so a complete pass through the entire invertible chain can be expressed as:
\begin{align*} 
f(\boldsymbol{\theta};\boldsymbol{x},\boldsymbol{\phi}_{inv}) = \boldsymbol{z} \numberthis \label{eqn:6}
\end{align*}
together with the inverse operation:
\begin{align*} 
f^{-1}(\boldsymbol{z};\boldsymbol{x},\boldsymbol{\phi}_{inv}) = \boldsymbol{\theta} \numberthis \label{eqn:7}
\end{align*}

This process can be interpreted as follows: the forward pass maps data-generating parameters to $\boldsymbol{z}$-space using conditional information of $\boldsymbol{x}$, while the inverse pass maps data points from $\boldsymbol{z}$-space to the data-generating parameters of interest using the same conditional information provided by the data. In the next section, we describe the optimization procedure used to match the outputs of $f^{-1}(\boldsymbol{z};\boldsymbol{x},\boldsymbol{\phi}_{inv})$ to the posterior $p(\boldsymbol{\theta}|\boldsymbol{x})$.

% Figures ACB and ACB chain
\begin{figure}
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{acb.png}
    \caption{The cACB}
    \label{fig:Fig.2a}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{acbchain.png}
    \caption{A chain of cACBs}
    \label{fig:Fig.2b}
  \end{subfigure}
  \caption{A diagram of the conditional version of the affine coupling block (cACB). \textbf{(a)} Each cABC consists of four internal networks performing the invertible operations described in the text; \textbf{(b)} In practice, we chain multiple cACBs to obtain higher representational capacity. Each cACB layer uses a fixed permutation to ensure that information about each parameter is encoded in each latent dimension of $\boldsymbol{z}$.} \label{fig:Fig.2}
\end{figure}

\subsection*{Summary Network}
Since in practice the conditioning data set $\boldsymbol{x}$ can have variable number of input points (e.g., trial sizes, time points) and exhibit various redundancies, the cINN can profit from some form of dimensionality reduction applied to the data. Ideally, we want to avoid hand-crafted summary statistics, and instead learn the most informative summary statistics directly from data. Therefore, instead of feeding the raw simulated or observed data to each ACB, we pass the data through an additional summary network to obtain a fixed-sized vector of learned summary statistics $\tilde{\boldsymbol{x}} = h(\boldsymbol{x};\boldsymbol{\phi}_{sum})$ and learn the parameters of the summary network $h$ jointly with those of the cINN chain via backpropagation. Thus, the current method remains completely end-to-end and is capable of generalizing to data sets of variable input size and structure.

\subsection*{Learning the Posterior}
The cINN learns to approximate the posterior of model parameters by optimizing  a maximum likelihood (ML) criterion. Broadly speaking, the goal of ML estimation is to find a set of parameters which maximize the probability of the data under a parametric model. In our case, we are interested in maximizing the expectation over all possible neural network parameters with respect to the parameters of the mathematical model:
\begin{align*} 
\boldsymbol{\phi}^{*} = \argmax_{\boldsymbol{\phi}}\mathbb{E}_{\boldsymbol{\theta} \sim p(\boldsymbol{\theta}|\boldsymbol{x})}\left[p(\boldsymbol{\phi}|\boldsymbol{\theta},\boldsymbol{x})\right] \numberthis \label{eqn:8}
\end{align*}
Applying Bayes' rule to the posterior over all neural network parameters we obtain:
\begin{align*} 
p(\boldsymbol{\phi}|\boldsymbol{\theta},\boldsymbol{x}) \propto p(\boldsymbol{\theta}|\boldsymbol{x},\boldsymbol{\phi})p(\boldsymbol{\phi})  \numberthis \label{eqn:9}
\end{align*}
Note, that by maximizing Eq.\ref{eqn:9} we are maximizing the posterior over model parameters of interest $p(\boldsymbol{\theta}|\boldsymbol{x},\boldsymbol{\phi})$. Thus, it remains to find a tractable expression for Eq.\ref{eqn:8} to be minimized by backpropagation given a finite number of simulated samples from the model. To this end, we recall that we can relate the pdf of $\boldsymbol{\theta}$ to that of $\boldsymbol{z}$ via the change of variable theorem:
\begin{align*} 
p(\boldsymbol{\theta}|\boldsymbol{x},\boldsymbol{\phi}) &= p(\boldsymbol{z})\left|\det\left(\frac{\partial \boldsymbol{z}}{\partial \boldsymbol{\theta}}\right)\right| \numberthis \label{eqn:10} \\ 
&= p\left(f(\boldsymbol{\theta};\boldsymbol{x},\boldsymbol{\phi})\right)\left|\det\left(\frac{\partial f}{\partial \boldsymbol{\theta}}\right)\right| \numberthis \label{eqn:11}
\end{align*}
where $\partial f/\partial \boldsymbol{\theta} = \boldsymbol{J}_{f}$ is the Jacobian of the learned transformation $f(\boldsymbol{\theta};\boldsymbol{x},\boldsymbol{\phi})$ with respect to the input. Both terms in Eq.\ref{eqn:11} are now tractable, since we have previously defined $\boldsymbol{z}$ as following a spherical unit Gaussian, that is, $p(\boldsymbol{z}) = (2\pi)^{-2/d}\exp(\norm{\boldsymbol{z}}_{2}^{2})$ and the determinant of the Jacobian is easily computed as $s_{1}(\boldsymbol{u}_{2}, \boldsymbol{x}) + s_{2}(\boldsymbol{v}_{1}, \boldsymbol{x})$ due to eqs. \ref{eqn:2} and \ref{eqn:3}. We can now formulate the ML loss as the Monte-Carlo approximation of the negative logarithm of Eq.\ref{eqn:8} for a batch of size $m$:
\begin{align*}
\mathcal{L}(\boldsymbol{\phi}) &= -\frac{1}{m}\sum_{i=1}^{m}\log\left(p(\boldsymbol{\phi}|\boldsymbol{\theta}^{(i)},\boldsymbol{x}^{(i)})\right) \numberthis \label{eqn:12} \\
&= -\frac{1}{m}\sum_{i=1}^{m}\log\left(p(\boldsymbol{\theta}^{(i)}|\boldsymbol{x}^{(i)},\boldsymbol{\phi})p(\boldsymbol{\phi})\right) \numberthis \label{eqn:13} \\
&= -\frac{1}{m}\sum_{i=1}^{m}\left(\frac{\norm{f(\boldsymbol{\theta}^{(i)};\boldsymbol{x}^{(i)},\boldsymbol{\phi})}_{2}^{2}}{2} + \log\left|\det\left(\boldsymbol{J}_{f}^{(i)}\right)\right|\right) + \tau\norm{\boldsymbol{\phi}}_{2}^{2} \numberthis \label{eqn:14}
\end{align*}
where we place a Gaussian prior over the neural network parameters with $\tau\equiv 1/\sigma^{2}$, corresponding to a standard $L2$-regularization.

Minimizing Eq.\ref{eqn:14} can be interpreted as searching for the optimal neural network parameters $\boldsymbol{\phi}^{*}$ which maximize the probability of model parameters $\boldsymbol{\theta}$ given data $\boldsymbol{x}$. This is exactly the probability we are concerned with in Bayesian inference. Note that our formulation maximizes the posterior of model parameters directly, in contrast to variational methods which optimize a lower bound on the posterior \cite{papamakarios2016fast, kingma2014auto}.
Once the backpropagation algorithm has settled to a local minimum of the ML loss, one can easily obtain samples from the approximate posterior $p(\boldsymbol{\theta}|\boldsymbol{x}=\boldsymbol{x}_{obs},\boldsymbol{\phi}=\boldsymbol{\phi}^{*})$, based on an observed dataset $\boldsymbol{x}_{obs}$, by repeatedly sampling $\boldsymbol{z}^{(l)} \sim \mathcal{N}_{d}(\boldsymbol{0},\boldsymbol{I})$, and then passing $\boldsymbol{z}^{(l)}$ in reverse to the cINN in order to compute $\boldsymbol{\theta}^{(l)} = f^{-1}(\boldsymbol{z}^{(l)};\boldsymbol{x}_{obs},\boldsymbol{\phi}^{*})$ for $l=1,...,L$. Figure 1b illustrates the inference phase of the method. It is worth noting that sampling a large number of parameter values from the approximate posterior takes a negligible amount of time, since it only requires a single pass through the cINN in reverse.
 
\subsection*{Training the Networks}
We train all cINNs and summary networks described in this paper jointly via backpropagation. For all following experiments, we use the Adam optimizer  with a starter learning rate of $10^{-3}$ and an exponential decay rate of $.95$. We set the weight regularization parameter $\tau$ to a value of $10^{-5}$. With these settings, we perform $50\ 000$ to $100\ 000$ iterations (network updates) for each of the examples in this paper, and report the results on the trained network. Note, that we did not perform an extensive search for optimal values of the cINN hyperparameter, but use a cINN with 10 ACBs all examples in this paper (see \textbf{SI} for details of the cINN). All networks were implemented in Python using the \textit{TensorFlow} library \cite{abadi2016tensorflow} and trained on a single-GPU machine equipped with NVIDIA\textsuperscript{\textregistered} GTX1060 graphics card. Regarding the data generation step, we use two training approaches. 

The first approach follows the classical approximate Bayesian computation approach to create a large \textit{reference table} or grid of the form $\boldsymbol{D} = \{\boldsymbol{x}^{(i)}, \boldsymbol{\theta}^{(i)}\}_{i=1}^{n}$. The reference table is then used as training data for the neural network and training continues for a pre-specified number of epochs through the entire reference table. A separate validation dataset is eventually used to assess the performance of the network. Training on large pre-simulated datasets separates the simulation from the training phase but can cause large memory overhead, as the reference table must be stored on disk and then loaded in chunks or in its entirety into memory. 

The second approach follows a different strategy, which resembles ideas from \textit{active learning} \cite{mnih2015human}. Correspondingly, a dataset, or a batch of datasets, is created on the fly and then passed through the neural network. This training regime has the advantage that the network never \textit{experiences} the same input data twice. Moreover, training can continue as long as the network keeps improving (i.e., the loss keeps decreasing), since overfitting in the classical sense is nearly impossible. However, if simulations are computationally expensive and researchers need to experiment with different networks or training hyperparameters, it might be beneficial to switch to the first regime, since simulation and training in the active learning regime are tightly intertwined.

\subsection*{Putting It All Together}

On an abstract level, our method requires three key ingredients: 1) a mathematical process model $q(\boldsymbol{\theta})$ capable of simulating data $\boldsymbol{x}$; 2) a prior distribution over the model parameters $p(\boldsymbol{\theta})$ encoding our prior beliefs about plausible parameter values; 3) an invertible neural network $f_{\boldsymbol{\phi}}$ capable of approximating a large enough family of probability distributions (see Figure 2). In practice, a chain of up to 10 ACBs should suffice to learn most distributions encountered in the cognitive or life sciences, since they tend to be unimodal and relatively simple (in contrast to the distributions required to represent images or words in a spoken language). From these three ingredients, a universal and reusable sampler can be designed for likelihood-free Bayesian estimation of both tractable and intractable mathematical models. \textbf{Algorithm} \ref{alg:1} describes the essential steps of the method using an arbitrary summary network and employing the active learning training regime.

\begin{algorithm}
\caption{Bayesian likelihood-free inference with invertible neural networks}\label{alg:1}
\begin{algorithmic}[1]
\State \emph{Training (via active learning):}
\Repeat
\State {Sample a batch of $\{\boldsymbol{\theta}^{(i)}\}_{i=1}^{m}$ from prior $p(\boldsymbol{\theta})$}
\State {Simulate a batch of datasets $\{\boldsymbol{x}^{(i)}\}_{i=1}^{m}$ by running $\boldsymbol{x}^{(i)} = q(\boldsymbol{\theta}^{(i)})$ for $i=1,...,m$}
\State {Pass $\{\boldsymbol{x}^{(i)}\}_{i=1}^{m}$ through summary network $h(\boldsymbol{x}^{(i)};\boldsymbol{\phi}_{sum})$ to obtain $\{\tilde{\boldsymbol{x}}^{(i)}\}_{i=1}^{m}$}
\State {Pass $\{\boldsymbol{\theta}^{(i)}\}_{i=1}^{m}$ and $\{\tilde{\boldsymbol{x}}^{(i)}\}_{i=1}^{m}$ through cINN $f(\boldsymbol{\theta}^{(i)};\boldsymbol{x}^{(i)},\boldsymbol{\phi}_{inv})$ to obtain $\{\boldsymbol{z}^{(i)}\}_{i=1}^{m}$}
\State {Compute ML loss $\mathcal{L}(\boldsymbol{\phi})$ according to Eq.\ref{eqn:14}}
\State {Update neural network parameters $\boldsymbol{\phi}$ via backpropagation}
\Until {convergence to $\boldsymbol{\phi}^{*}$}
\State \emph{Inference (given observed or test data $\boldsymbol{x}_{obs}$):}
\State {Summarize the observed data by computing $\tilde{\boldsymbol{x}}_{obs} = h(\boldsymbol{x}_{obs},\boldsymbol{\phi}_{sum}^{*})$}
\For{$l = 1,...,L$}
\State {Sample $\boldsymbol{z}^{(l)} \sim \mathcal{N}_{d}(\boldsymbol{0},\boldsymbol{I})$}
\State {Compute $\boldsymbol{\theta}^{(l)} = f^{-1}(\boldsymbol{z}^{(l)};\tilde{\boldsymbol{x}}_{obs},\boldsymbol{\phi}_{inv})$}
\EndFor
\State {\textbf{end for}}
\State {Use $\{\boldsymbol{\theta}^{(l)}\}_{l=1}^{L}$ to approximate the posterior $p(\boldsymbol{\theta}|\boldsymbol{x}_{obs})$}
\end{algorithmic}
\end{algorithm}

The backpropagation algorithm works by computing the gradients of the loss function with respect to the parameters of the neural networks and then adjusting the parameters, so as to drive the loss function to a local minimum. We experienced no instability or convergence issues during training with the ML loss. Note, that steps $12-15$ of \textbf{Algorithm} \ref{alg:1} can be executed in parallel with GPU support. 

In what follows, we apply the method to a toy Bayesian regression example with conjugate priors, and then use it to estimate the parameters of challenging models from population dynamics, cognitive science, epidemiology, and genetics. 

\section*{Results}

To assess the performance of our method on the following application examples, we consider a number of different metrics. To assess the precision of point estimates (posterior means), we compute the normalized root mean squared error (NRMSE) and the coefficient of determination ($R^{2}$) between estimated and true parameter values. To assess the recovery of the full posterior, we compute the Kullback-Leibler (KL) divergence \cite{hershey2007approximating} between the true and the approximate distributions for the toy example, and use simulation-based calibration (SBC, \cite{talts2018validating}) for the other examples where the analytic posterior is not available in closed-form. Details for computing the NRMSE, $R^2$, and SCB can be found in the \textbf{SI}. Code for reproducing the results on all following examples, as well as all network implementations, is freely available at: \href{https://github.com/stefanradev93/cINN}{https://github.com/stefanradev93/cINN}.

\subsection*{Toy Example – Bayesian Regression}

As a proof-of-concept, we demonstrate the utility of our method in recovering the true analytic posteriors of the regression coefficients of a conjugate Bayesian regression model. To set the stage, assume we have observed a dataset $\boldsymbol{D} = \{(\boldsymbol{x}^{(i)},y^{(i)})\}_{i=1}^{n}$ with $\boldsymbol{x} \in \mathbb{R}^{d}$ and $y \in \mathbb{R}$. We stack all $\boldsymbol{x}^{(i)}$ row-wise in a design matrix $\boldsymbol{X}$ and model the vector of outcomes $\boldsymbol{y}$ as being conditionally Gaussian given $\boldsymbol{X}$, that is, $\boldsymbol{y} \sim \mathcal{N}_{n}(\boldsymbol{X}\boldsymbol{\theta},a^{-1}\boldsymbol{I})$ where $\boldsymbol{\theta} \in \mathbb{R}^{d}$ and $a$ is the precision (inverse noise variance, $a \equiv 1/\sigma_{y}^{2}$). We place a $d$-dimensional diagonal Gaussian prior on the regression coefficients centered at $0$: $\boldsymbol{\theta} \sim \mathcal{N}_{d}(\boldsymbol{0},b^{-1}\boldsymbol{I})$ where $b$ is the precision of the prior ($b \equiv 1/\sigma_{\boldsymbol{\theta}}^{2}$). Thus, the likelihood $p(\boldsymbol{D}|\boldsymbol{\theta})$ admits the following proportionality:
\begin{align*}
p(\boldsymbol{D}|\boldsymbol{\theta}) \propto \exp\left(-\frac{a}{2}\left(\boldsymbol{y}-\boldsymbol{X}\boldsymbol{\theta}\right)^{T}\left(\boldsymbol{y} - \boldsymbol{X}\boldsymbol{\theta}\right)\right) \numberthis 
\end{align*}
Since the prior of $\boldsymbol{\theta}$ is conjugate to the likelihood (both are Gaussian distributions), the posterior of $\boldsymbol{\theta}$ is also Gaussian, given by:
\begin{align*}
p(\boldsymbol{\theta}|\boldsymbol{D}) \propto \exp\left(-\frac{a}{2}\left(\boldsymbol{y}-\boldsymbol{X}\boldsymbol{\theta}\right)^{T}\left(\boldsymbol{y} - \boldsymbol{X}\boldsymbol{\theta}\right)-\frac{b}{2}\boldsymbol{\theta}^{T}\boldsymbol{\theta}\right) \numberthis 
\end{align*}
Therefore, the posterior has the form $p(\boldsymbol{\theta}|\boldsymbol{D}) = \mathcal{N}_{d}(\boldsymbol{\theta}|\boldsymbol{\mu},\boldsymbol{\Lambda}^{-1})$ where $\boldsymbol{\Lambda}$ denotes the posterior precision matrix (inverse covariance matrix), $\boldsymbol{\mu}$ the posterior mean vector, which are computed as follows:
\begin{align*}
\boldsymbol{\Lambda} &= a\boldsymbol{X}^{T}\boldsymbol{X} + b\boldsymbol{I} \numberthis \\
\boldsymbol{\mu} &= a\boldsymbol{\Lambda}^{-1}\boldsymbol{X}^{T}\boldsymbol{y} \numberthis
\end{align*} 
Thus, for known $a$ and $b$, the posterior of $\boldsymbol{\theta}$ can be easily computed. Even though in real-world applications $a$ is usually not known and a hierarchical model is used instead, the current example is good for testing the utility of our method.

For the following application, we set $d=4$, and $a=b=1$. The design matrices for each iteration contain a variable number $n$ of \textit{i.i.d.} data points drawn from a unit Gaussian $\boldsymbol{x}^{(i)} \sim \mathcal{N}_{4}(\boldsymbol{0},\boldsymbol{I})$ for $i=1,...,n$. The number of trials is drawn from a uniform distribution $n \sim \mathcal{U}(50, 500)$ at each training iteration (Lines $2$-$9$ of \textbf{Algorithm} \ref{alg:1}). Training the networks took approx. half a day with the active learning approach. Inference on $1000$ datasets with $2000$ posterior samples per parameter took approx. $5.5$ seconds.

The results on the toy Bayesian regression are depicted in \autoref{fig:Fig.3}. The approximate posterior means show negligible deviations from the analytic posterior means as quantified by very small NRMSEs (as small as $0.002$) and very high $R^{2}$ (as high as $1.0$) over all $n$ sampled during training. This suggests near-perfect estimation of the true posterior means. Further, the estimates become increasingly more accurate, as the number of data points $n$ increases. An inspection of the posterior variances over the different $n$ reveals that the estimated variance follows closely the decrease in analytic variance with increasing $n$. However, the analytic variance is slightly underestimated at smaller $n$ and slightly overestimated at larger $n$. This pattern is also revealed by the KL divergence plot (see \textbf{SI}). This result might be attributable to an underexpressive summary network; another possibility is that the networks need to be trained longer with smaller learning rate decay. 
\begin{figure}[H]
\centering
\begin{subfigure}{.49\textwidth}
    \includegraphics[width=\textwidth]{Regression_joint.png}
    \caption{Analytic vs. estimated means joint plot ($n=500$)}
    \label{fig:Fig.3a}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
	\begin{subfigure}{.95\textwidth}
 		\includegraphics[width=\textwidth]{Regression_density.png}
    	\caption{Full analytic vs. estimated posteriors ($n=500$)}
    \label{fig:Fig.3b}
	\end{subfigure}
	\begin{subfigure}{.95\textwidth}
 		\includegraphics[width=\textwidth]{Regression_scatter.png}
    	\caption{Analytic means recovery ($n=500$)}
    \label{fig:Fig.3c}
	\end{subfigure}
\end{subfigure}
\begin{subfigure}{.47\textwidth}
 		\includegraphics[width=\textwidth]{Regression_metrics.png}
    	\caption{Performance over all $n$}
    \label{fig:Fig.3d}
\end{subfigure}
\begin{subfigure}{.52\textwidth}
 		\includegraphics[width=\textwidth]{Regression_variance.png}
    	\caption{Analytic vs. estimated variance over all $n$}
    \label{fig:Fig.3e}
\end{subfigure}
\caption[short]{Results on the Bayesian toy regression example. \textbf{(a)} Pair-plots of the analytic vs. estimated posterior means on the whole validation sample. We observe a near-perfect overlap between analytic and estimated posterior means and no spurious covariances; \textbf{(b)} Some example draws from the estimated posteriors. Visual inspections reveals a close match between analytic and estimated posteriors; \textbf{(c)} Posterior mean recovery is almost perfect at $n=500$; \textbf{(d)} NRMSE and $R^{2}$ over all $n$. Performance improves with increasing number of data points; \textbf{(e)} Analytic vs. estimated variance over all $n$. The analytic variance is slightly underestimated at lower $n$ and slightly overestimated at higher $n$.} \label{fig:Fig.3}
\end{figure}

\subsection*{Example 1 - The Ricker Model}
Discrete population dynamics models describe how the number of individuals in a population changes over discrete units of time \cite{wood2010statistical}. In particular, the Ricker model describes the number of individuals $x_{t+1}$ in generation $t+1$ as a function of the number of individuals in the previous generation $t$ by the following non-linear equation:
\begin{align*}
x_{t} &\sim Pois(\rho N_{t}) \numberthis \\
N_{t+1} &= rN_{t}e^{-N_{t} + \epsilon_{t}} \numberthis 
\end{align*}
for $t = 1,...,T$ where $N_{t}$ is the expected number of individuals at time $t$, $r$ is the growth rate, $\rho$ is a scaling parameter and $\epsilon_{t} \sim \mathcal{N}(0, \sigma^{2})$ is random Gaussian noise \cite{mestdagh2018prepaid}. The likelihood function for the Ricker model is not available in closed-form, and the model is known to exhibit chaotic behavior. Thus, it is a suitable candidate for likelihood-free inference.  The parameter estimation task is thus to recover $\boldsymbol{\theta}=(\rho,r,\sigma)$ from the observed one-dimensional time-series data $\boldsymbol{x}=(x_{1},x_{2},...,x_{T})$ where each $x_{t} \in \mathbb{N}$.

During training of the networks, we simulate time-series from the Ricker model with varying lengths. The number of time points $T$ is drawn from a uniform distribution $T \sim \mathcal{U}(100, 500)$ at each training iteration (see the \textbf{SI} for more details about the simulation). Training the networks took approx. half a day with the active learning approach. Inference on $1000$ datasets with $2000$ posterior samples per parameter took approx. $6$ seconds.

What if the data does not contain any information about a particular parameter? In this case, any good estimation method should detect this, and return the prior of the particular parameter. To test this, we append a random uniform variable $u \sim \mathcal{U}(0, 1)$ to the parameter vector $\boldsymbol{\theta}$ and train the model with this additional dummy parameter. We expect that the networks learn to ignore this dummy parameter, that is, the estimated posterior of $u$ is (approximately) equal to the uniform prior. 

The results on the Ricker model are depicted in \autoref{fig:Fig.4}. As evident from the graphs, parameter recovery becomes better when more time points with data are available (\autoref{fig:Fig.4c}). At $T=500$, the NRMSEs range between $0.015$ and $0.063$, and the $R^{2}$ metrics between $0.997$ and $0.952$, indicating very good recovery of the posterior means (\autoref{fig:Fig.4a}). The parameter $\sigma$ seems to be the hardest to recover. Inspecting the full posteriors, we further see that the posterior distribution of the dummy noise variable $u$ closely resembles the prior, as expected due to the complete lack of mutual information between the data $x$ and $u$ (\autoref{fig:Fig.4b}). Finally, the plots of the rank statistic computed for SCB suggest no systematic distortions of the posterior across all parameters (\autoref{fig:Fig.4d}). Interpreting deviations from uniformity according to \cite{talts2018validating}, the approximate posteriors of $r$ and $\rho$ slightly underestimate the true posterior means, whereas the approximate posterior of $\sigma$ tends to overestimate the true posterior variance. These deviations appear to be due to the fact that recovery worsens at extreme values of the parameters. This is unsurprising, as the data generated with these parameters is highly implausible, which in some cases might even render a model unidentifiable.

\begin{figure}[H]
\centering
\begin{subfigure}{.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Ricker_scatter.png}
    \caption{Parameter recovery ($T=500$)}
    \label{fig:Fig.4a}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Ricker_density.png}
    \caption{Example posterior samples ($T=500$)}
    \label{fig:Fig.4b}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Ricker_metrics.png}
    \caption{Performance over all $T$s}
    \label{fig:Fig.4c}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Ricker_sbc.png}
    \caption{Simulation-based calibration (SBC)}
    \label{fig:Fig.4d}
\end{subfigure}
\caption[short]{Results on the Ricker model. \textbf{(a)} Parameter recovery for the maximum number of generations used during training ($T=500$); \textbf{(b)} Example posteriors for three test datasets. We observe that the posterior of the uniform noise variable $u$ is equal to the prior, i.e., the method detects that no information is present in data for this variable; \textbf{(c)} NRMSE and $R^{2}$ performance metrics over all $T$s used in training. We observe that the recovery remains good over all $T$s, and becomes progressively better as more data is available; \textbf{(d)} Plots of the rank statistics indicative of the accuracy of the full posterior. Accordingly, the approximate posteriors of $r$ and $\rho$ slightly underestimate the true posterior means, whereas the approximate posterior of $\sigma$ tends to overestimate the true posterior variance.} \label{fig:Fig.4}
\end{figure}

\subsection*{Example 2 - The Lévy-Flight Model}
Evidence accumulator models (EAMs) describe human decision making by a set of neurocognitively motivated parameters \cite{ratcliff2008diffusion}. EAMs are most often applied to choice reaction times (RT) data to obtain an estimate of the neurocognitive processes governing observed RT distributions in human (or animal) participants. Most EAM variants share four underlying assumptions: \textit{i)} information about a stimulus (response option) is accumulated continuously through time; \textit{ii)} stochasticity in the form of noisy accumulation ensures variability; \textit{iii)} empirical response times can be decomposed into a decision time component and a non-decision time component accounting for pre-decisional perceptual (encoding time) and post-decisional motor processes (response execution); and \textit{iv)} a decision is met when the activation of an accumulator reaches a threshold. In its most general formulation, the forward model of EAMs takes the form of a stochastic differential equation given by \cite{usher2001time}:
\begin{align*} 
dx = vdt + cd\xi  \numberthis \label{eqn:stillno}
\end{align*}
where $dx$ denotes a change in activation of an accumulator, $v$ denotes the average speed of information accumulation (often termed the drift rate), and $d\xi$ represents a stochastic additive component, usually modeled as following a Gaussian distribution centered around $0$: $d\xi \sim \mathcal{N}(0, c^{2})$.

EAMs are particularly amenable for likelihood-free inference, since the likelihood of some members of this model family turn out to be intractable \cite{miletic2017parameter}. This intractability has precluded many interesting applications and empirically driven model refinements. Here, we apply our method to estimate the parameters of the recently proposed Lévy-Flight Model (LFM, \cite{voss2019sequential}). The LFM assumes an \textit{alpha-stable} noise distribution of the evidence accumulation process in order to model "jumps" in the decision process. However, the inclusion of \textit{alpha-stable} noise leads to a model with intractable likelihood; further, to our knowledge, a fully Bayesian treatment of the model is still missing in the literature. The forward equation of the LFM is given by:
\begin{align*}
dx &= vdt + \xi dt^{1/\alpha} \numberthis \label{eqn:stillno2} \\
\xi &\sim AlphaStable(\alpha,0,1,0) \numberthis \label{eqn:stillno3}
\end{align*}
The LFM has three additional parameters: the threshold $a$ determining the amount of evidence needed for the termination of a decision process; a relative starting point, $zr$, determining the amount of starting evidence available to the accumulator before the actual decision alternatives are presented; and an additive non-decision time $t_{0}$. 

During training of the networks, we simulate response times data from two experimental conditions with two different drift rates (see \textbf{SI} for details of the simulation), since this such a design is often encountered in psychological research. The parameter estimation task is thus to recover the parameters $\boldsymbol{\theta} = (v_{0}, v_{1}, a, t_{0}, zr, \alpha)$ from two-dimensional \textit{i.i.d.} RT data $\boldsymbol{X} = (\boldsymbol{x}_{1},\boldsymbol{x}_{2},...,\boldsymbol{x}_{n})$ containing variable number or RT trials. The number of trials is drawn from a uniform distribution $n \sim \mathcal{U}(100, 1000)$ at each training iteration. Training the networks took a little less than a day with the active learning approach. Inference on $1000$ datasets with $2000$ posterior samples per parameter took approx. $7.39$ seconds. 

\begin{figure}[H]
\centering
\begin{subfigure}{.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Levy_scatter.png}
    \caption{Parameter recovery ($n=1000$)}
    \label{fig:Fig.5a}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Levy_density.png}
    \caption{Example posterior samples ($n=1000$)}
    \label{fig:Fig.5b}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Levy_metrics.png}
    \caption{Performance over all trial numbers}
    \label{fig:Fig.5c}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Levy_sbc.png}
    \caption{Simulation-based calibration (SBC)}
    \label{fig:Fig.5d}
\end{subfigure}
\caption[short]{Results on the LFM model. \textbf{(a)} Parameter recovery for the maximum number of trials used during training ($n=1000$); \textbf{(b)} Example posteriors for three test datasets; \textbf{(c)} NRMSE and $R^{2}$ performance metrics over all $n$ trials used during training. Again, we observe that the recovery remains overall very good, and becomes progressively better as more data is available; \textbf{(d)} Plots of the rank statistics indicative of the accuracy of the full posterior. Accordingly, the approximate posteriors tend to overestimate the true posterior variance.} \label{fig:Fig.5}
\end{figure}

The results on the LFM model are depicted in \autoref{fig:Fig.5}. To our knowledge, this is the first Bayesian treatment of the LFM, as its intractability makes traditional methods prohibitively slow. We observe excellent recovery of all LFM parameters with NRMSEs ranging between $0.008$ and $0.048$ and $R^{2}$ between $0.972$ and $0.999$. Further, estimation remains very good across all trial sizes, with goodness increasing as more trials become available. The parameter $\alpha$ appears to be most challenging to estimate, requiring more data for good estimation, whereas the non-decision time parameter $t_{0}$ is almost perfectly reconstructed for all trial sizes. Last, inspecting the SCB plots, we notice that the histograms tend to be slightly peaked, indicating a slight overestimation of the posterior variance \cite{talts2018validating}.

\subsection*{Example 3 – The Stochastic SIR Model}
Compartmental models in epidemiology are used to describe the stochastic dynamics of infectious diseases as they spread over a population of individuals \cite{sahneh2017gemfsim,keeling2011modeling, hethcote2000mathematics}. The parameters of compartmental models encode important characteristics of diseases, such as the rates of infection or recovery from the disease. The stochastic SIR model describes the transition dynamics of $N$ individuals between three discrete states: susceptible ($S$), infected ($I$), and recovered ($R$). The transition dynamics are given by the following equations:
\begin{align*}
\triangle S &= -\triangle N_{SI} \numberthis \\
\triangle I &= \triangle N_{SI} - \triangle N_{IR} \numberthis \\
\triangle R &= \triangle N_{IR} \numberthis \\
\triangle N_{SI} &\sim Binomial(S, 1 - \exp\left(-\beta\frac{I}{N}\triangle t \right)) \numberthis \\
\triangle N_{IR} &\sim Binomial(I, 1 - \exp\left(-\gamma\triangle t \right)) \numberthis 
\end{align*}
where $S + I + R = N$ give the number of susceptible, infected, and recovered individuals, respectively. The parameter $\beta$ controls the transition rate from being susceptible to infected, and $\gamma$ controls the transition rate from being infected to recovered (see \autoref{fig:Fig.6}). The number of individuals moving from $S$ to $I$, given by $\triangle N_{SI}$, and the number of people moving from $I$ to $R$, given by $\triangle N_{IR}$, over a time interval $\triangle t$ are modeled as binomial random variables. The above listed stochastic system has no known analytic solution and thus requires numerical simulation methods for recovering parameter values from data. Cast as a parameter estimation task, the challenge is to recover $\boldsymbol{\theta} = \{\beta,\gamma\}$ from three dimensional time-series data $\boldsymbol{X} = (\boldsymbol{x}_{1},\boldsymbol{x}_{2},...,\boldsymbol{x}_{T})$ where each $\boldsymbol{x}_{t} \in \mathbb{N}^{3}$ is a triple containing the number of susceptible ($S$), number of infected ($I$), and recovered ($R$) individuals at time $t$. 

During training of the networks, we simulate time-series from the stochastic SIR model with varying lengths. The number of time points $T$ is drawn from a uniform distribution $T \sim \mathcal{U}(200, 500)$ at each training iteration (see the \textbf{SI} for more details about the simulation). Usually, at lower $T$s, the system has not converged to an equilibrium (i.e., not all individuals have transitioned from being $I$ to $R$). Thus, it is especially interesting to see if our method can recover the rate parameters, even if the process dynamics are still unfolding over time. Training the networks took approx. half a day with the active learning approach. Inference on $1000$ datasets with $2000$ posterior samples per parameter took approx. $1.1$ seconds. 

\begin{figure}[H]
\centering
\begin{subfigure}{.44\textwidth}
    \includegraphics[width=\textwidth]{SIR_plot.png}
    \caption{Example SIR timeseries with $\beta=0.5$ and $\gamma=0.2$}
    \label{fig:Fig.6a}
\end{subfigure}
\begin{subfigure}{.55\textwidth}
    \includegraphics[width=\textwidth]{SIR_states.png}
    \caption{State-transition diagram of the SIR model}
    \label{fig:Fig.6b}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
    \includegraphics[width=\textwidth]{SIR_scatter.png}
    \caption{Parameter recovery ($T=500$)}
    \label{fig:Fig.6c}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
    \centering
    \begin{subfigure}{.49\textwidth}
    	\includegraphics[width=\textwidth]{SIR_metrics.png}
    	\caption{Performance over all $T$s}
    	\label{fig:Fig.6d}
	\end{subfigure}
	\begin{subfigure}{.49\textwidth}
    	\includegraphics[width=\textwidth]{SIR_variance.png}
    	\caption{Posterior variance over all $Ts$}
    	\label{fig:Fig.6e}
	\end{subfigure}
	\begin{subfigure}{.49\textwidth}
    	\includegraphics[width=\textwidth]{SIR_density.png}
    	\caption{Example posterior samples ($T=500$}
    	\label{fig:Fig.6f}
	\end{subfigure}
	\begin{subfigure}{.49\textwidth}
    	\includegraphics[width=\textwidth]{SIR_sbc.png}
    	\caption{Simulation-based calibration (SBC)}
    	\label{fig:Fig.6g}
	\end{subfigure}
\end{subfigure}
\caption[short]{Results on the stochastic SIR model. \textbf{(a)} Example SIR timeseries generated with $\beta=0.5$ and $\gamma=0.2$; \textbf{(b)} State transition diagram of the SIR model; \textbf{(c)} Parameter recovery depicting also NRMSE and $R^{2}$ metrics; \textbf{(d)} NRMSE and $R^{2}$ performance over all $T$s seen by the networks during training. We observe similar patterns as in the previous examples; \textbf{(e)} Posterior variances of the SIR parameters over all $T$s; \textbf{(f)} Example full posteriors of the parameters recovered from three test datasets; \textbf{(g)} Plots of the rank statistic, according to which the posterior of $\beta$ slightly overestimates the true mean.} \label{fig:Fig.6}
\end{figure}

The results on the SIR model are depicted in \autoref{fig:Fig.6}. Similar to the previous examples, we observe very good recovery of the true parameters, with NRMSE at $T=500$ around $0.04$, and $R^{2}$s around $0.98$. Further, we observe decent performance even at smaller $T$s, with performance increasing as $T$ increases. Conversely, the estimated posterior variance drops as $T$ increases, capturing the fact that more information becomes available to the networks. Finally, the SCB plots indicate a slight underestimation of the true posterior means by the estimated posterior means. This trend is visible when $\beta$ and $\gamma$ both assume very similar values, and the generated timeseries are far from equilibrium at the final time point $T$. Thus, such datasets contain very little information about the parameters given the considered time range of $T_{max}=500$.

\subsection*{Example 4 - Single-Cell RNA Sequencing}
Single-cell RNA sequencing (scRNA-seq) is a method to uncover the dynamics of gene expression within single cells \cite{zappia2017splatter, ozsolak2011rna}. Simulation models for scRNA-seq attempt to mimic the process of sequencing real data samples by combining statistical and algorithmic procedures. The recently developed \textit{Splat} simulation model \cite{zappia2017splatter} implements a hierarchical model where the mean expression levels for multiple genes are samples from a Gamma distribution, and the number of times a gene has been sequenced in a cell is then sampled from a Poisson distribution. The output of the \textit{Splat} simulation is thus a matrix $\boldsymbol{X}$ of \textit{Gene x Cell} counts. \autoref{fig:Fig.7a} depicts the \textit{Splat} algorithm for simulating scRNA-seq data \cite{zappia2017splatter}.
\begin{table} 
\centering
\caption{Splat target parameters estimated by our method}
\begin{tabular}{lll}
Parameter & Name & Description\\
\midrule
$\alpha$ & Mean shape & Shape of the mean gene expression gamma distribution \\
$\beta$ & Mean rate & Rate of the mean gene expression gamma distribution \\
$\mu^{L}$ & Library size location & Location of the library size log-normal distribution \\
$\sigma^{L}$ & Library size scale & Scale of the library size log-normal distribution \\
$\pi^{O}$ & Outlier probability & Probability that a gene is an expression outlier \\
$\mu^{O}$ & Outlier location & Location of the expression outlier factor log-normal distribution \\
$\sigma^{O}$ & Outlier scale & Scale of the expression outlier factor log-normal distribution \\
$\phi$ & Common BCV & Common BCV dispersion across all genes \\
\bottomrule
\end{tabular}
\label{table:Table 1}
\end{table}
As a last example for our method, we use simulations from the \textit{Splat} model and attempt to recover the data-generating parameters. This is a challenging task for any Bayesian method, as the data-generating mechanism is a complicated algorithm, and no likelihood function for joint estimation of the parameters is available. We simulate $200\ 000$  \textit{Gene x Cell} count matrices with different parameter settings (see \textbf{SI} for details of the simulation). Each count matrix contains the information about $40$ genes sequenced in $100$ different cells, that is, each $\boldsymbol{X} \in \mathbb{R}^{40\times100}$. The parameters considered for estimation, along with a short description, are listed in \autoref{table:Table 1}. The parameter estimation task is thus to recover $\boldsymbol{\theta} = (\alpha,\beta,\mu^{L},\sigma^{L},\pi^{O},\mu^{O},\sigma^{O},\phi)$ from an observed count matrix $\boldsymbol{X}$. We train the networks for 50 epochs through the entire dataset and evaluate the performance on a separate validation set of $300$ count matrices. To stabilize training and avoid exploding gradients due to large counts in the input matrices, we apply a log transformation to the data. Simulating the data took approx. $8$ hours. Training the networks took approx. one day with the reference table approach. Inference on $300$ datasets with $2000$ posterior samples per parameter took approx. $1.5$ seconds. 
\begin{figure}[H]
\centering
\begin{subfigure}{.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Splatter_plot.png}
    \caption{The \textit{Splat} simulation diagram. Adapted after \cite{zappia2017splatter}.}
    \label{fig:Fig.7a}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Splatter_scatter.png}
    \caption{Parameter recovery }
    \label{fig:Fig.7b}
\end{subfigure}
\caption[short]{Results on the \textit{Splat} scRNA simulation model. \textbf{(a)} The \textit{Splat} simulation diagram; \textbf{(b)} Parameter recovery.} \label{fig:Fig.7}
\end{figure}
The results on the scRNA example are depicted in \autoref{fig:Fig.7}. We observe excellent parameter recovery on the validation set. \textbf{TODO: Train the full method. These results are preliminary}.

\section*{Discussion}

In the current work, we proposed and explored a novel end-to-end likelihood-free method which uses invertible neural networks to perform approximate Bayesian inference on any mathematical process model. We demonstrated the utility of the method by applying it to models from various scientific domains dealing with several different data formats and data-generating mechanisms. Further, we explored two possible training approaches suitable for different simulation scenarios, namely, an active learning approach, and a reference-table approach. Both training approaches lead to excellent recovery of the true parameters throughout the examples considered in the current work.

Our method combines the universal approximation power of deep learning methods \cite{goodfellow2016deep} with the crucial uncertainty quantification assets of Bayesian inference \cite{kendall2017uncertainties, gelman2013bayesian}. Besides being capable of performing full Bayesian inference on intractable mathematical models, our method provides a general framework for designing reusable \textit{parameter estimation machines} for various research domains. Moreover, it can also prove as a viable alternative in modeling contexts where standard inference methods are available, but inference is nevertheless computationally inconvenient. 

Inspired by previous machine learning approaches to likelihood-free inference \cite{radev2019towards, hwang2018conditional, mestdagh2018prepaid, raynal2018abc, jiang2017learning, lueckmann2017flexible, papamakarios2016fast}, our method shares many of the advantages of these methods and further overcomes some of their important limitations. 

First, the introduction of separate summary and invertible networks renders the method independent of the shape or the size of the observed data. The summary network learns a fixed-size vector representation of the data in an automatic, data-driven manner. Since the summary network is optimized jointly with the invertible network, the learned data representation is encouraged to be maximally informative for parameter inference. This is particularly useful in settings where appropriate summary statistics are not known and, as a consequence, relevant information is lost through the choice of suboptimal summary function. However, if highly informative or even \textit{sufficient} statistics are available in a given domain, one might dispose with the summary network altogether and feed these statistics directly to the invertible network.

Second, we showed that the ML loss directly maximizes the posterior over model parameters of interest. This is in contrast to ELBO-based methods which optimize a lower-bound on the posterior \cite{papamakarios2016fast, kingma2014auto}. Therefore, posterior inference is exact when the ML is globally minimized \cite{kingma2018glow, dinh2016density}. This theoretical claim is further confirmed by our results. Since researchers are often interested in some summary of the posterior (e.g., posterior means or variances), we also showed that our method exhibits excellent recovery of the posterior means throughout all examples. Further, parameter recovery becomes better with increasing number of observations, whereas the posterior variance of the parameters decreases. These are important and highly desirable properties of any Bayesian parameter estimation method, as it mirrors the increase in information following increasing number of observations. 

Third, the largest computational cost of our method is paid during training. Once trained, the networks can be used and reused to perform inference on large numbers of datasets within seconds and across a given research domain. Indeed, there are many instances of research domains where a single model is extensively explored and independently fitted by multiple researches to test scientific hypotheses \cite{voss2019sequential, zappia2017splatter, ratcliff2008diffusion, de2002fitting}. These research domains are expected to benefit the most from learning the \textit{model universe} once and then inverting the model multiple times for fast inference on multiple datasets. In this regard, our method is similar to the recently introduced prepaid method \cite{mestdagh2018prepaid} which uses a database of pre-computed summary statistics and nearest-neighbors for inference. Note, however, that our method does not need to store training data, since the \textit{knowledge} about the relationship between data and parameters is compressed into the networks' weights. This not only makes the global sharing of pre-trained parameter estimation networks across researchers extremely easy, but also makes their local storage very efficient. Moreover, all computations involved in our method benefit from a high degree of parallelism and can thus utilize the advantages of modern GPUs.

These advantages notwithstanding, some limitations of our method deserve mention. Even though high-level deep learning libraries, such as \textit{TensorFlow} or \textit{Torch}, allow for rapid and relatively straightforward development of various neural network architectures, the implementational burden associated with the current method is still reasonably high. In order to ease the understanding and independent application of the method, we provide fully functioning code to reproduce and study all of the examples tackled in this paper (\href{https://github.com/stefanradev93/cINN}{https://github.com/stefanradev93/cINN}). In addition, we also provide implementation of all tools for performance validation used throughout the paper. Moreover, we are currently developing a general user-friendly software, which should abstract away most of the methodological complexities from the user. Another potential shortcoming of the method is the seemingly overwhelming number of hyperparameters that might require fine-tuning by the user for optimal performance on a given task. However, we observe that many of the default hyperparameter values are sufficient to achieve excellent performance, and starting with a relatively large default network of $10$ ACBs does not appear to hurt performance or destabilize training, even if the mathematical model to be learned is relatively simple. We expect that a single architecture should be able to perform well on almost all models from a given domain (i.e., a single architecture for decision-making models). Future research should investigate the question of generality by applying the method to challenging parameter estimation tasks across different research domains.


\acknow{We thank Jeffrey Rouder, Raphael Hartmann, David Izydorczyk, Hannes Wendler, Satya Almasian, and Karin Prillinger for their invaluable comments and suggestions that greatly improved the manuscript.}

\showacknow % Display the acknowledgements section

% Bibliography
\bibliography{references}

\end{document}