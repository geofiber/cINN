\begin{thebibliography}{10}

\bibitem{zappia2017splatter}
Zappia L, Phipson B, Oshlack A (2017) Splatter: simulation of single-cell rna
  sequencing data.
\newblock {\em Genome biology} 18(1):174.

\bibitem{beaumont2002approximate}
Beaumont MA, Zhang W, Balding DJ (2002) Approximate bayesian computation in
  population genetics.
\newblock {\em Genetics} 162(4):2025--2035.

\bibitem{palestro2018likelihood}
Palestro JJ, Sederberg PB, Osth AF, Van~Zandt T, Turner BM (2018) {\em
  Likelihood-free methods for cognitive science}.
\newblock (Springer).

\bibitem{usher2001time}
Usher M, McClelland JL (2001) The time course of perceptual choice: the leaky,
  competing accumulator model.
\newblock {\em Psychological review} 108(3):550.

\bibitem{hwang2018conditional}
Hwang SJ, Tao Z, Kim WH, Singh V (2018) Conditional recurrent flow: Conditional
  generation of longitudinal samples with applications to neuroimaging.
\newblock {\em arXiv preprint arXiv:1811.09897}.

\bibitem{lueckmann2017flexible}
Lueckmann JM, et~al. (2017) Flexible statistical inference for mechanistic
  models of neural dynamics in {\em Advances in Neural Information Processing
  Systems}.
\newblock pp. 1289--1299.

\bibitem{wood2010statistical}
Wood SN (2010) Statistical inference for noisy nonlinear ecological dynamic
  systems.
\newblock {\em Nature} 466(7310):1102.

\bibitem{hethcote2000mathematics}
Hethcote HW (2000) The mathematics of infectious diseases.
\newblock {\em SIAM review} 42(4):599--653.

\bibitem{csillery2010approximate}
Csill{\'e}ry K, Blum MG, Gaggiotti OE, Fran{\c{c}}ois O (2010) Approximate
  bayesian computation (abc) in practice.
\newblock {\em Trends in ecology \& evolution} 25(7):410--418.

\bibitem{toni2009simulation}
Toni T, Stumpf MP (2009) Simulation-based model selection for dynamical systems
  in systems and population biology.
\newblock {\em Bioinformatics} 26(1):104--110.

\bibitem{turner2014generalized}
Turner BM, Sederberg PB (2014) A generalized, likelihood-free method for
  posterior estimation.
\newblock {\em Psychonomic bulletin \& review} 21(2):227--250.

\bibitem{sunnaaker2013approximate}
Sunn{\aa}ker M, et~al. (2013) Approximate bayesian computation.
\newblock {\em PLoS computational biology} 9(1):e1002803.

\bibitem{mertens2018abrox}
Mertens UK, Voss A, Radev S (2018) Abroxâ€”a user-friendly python module for
  approximate bayesian computation with a focus on model comparison.
\newblock {\em PloS one} 13(3):e0193981.

\bibitem{frazier2018asymptotic}
Frazier DT, Martin GM, Robert CP, Rousseau J (2018) Asymptotic properties of
  approximate bayesian computation.
\newblock {\em Biometrika} 105(3):593--607.

\bibitem{radev2019towards}
Radev ST, Mertens UK, Voss A, K{\"o}the U (2019) Towards end-to-end
  likelihood-free inference with convolutional neural networks.
\newblock {\em British Journal of Mathematical and Statistical Psychology}.

\bibitem{mestdagh2018prepaid}
Mestdagh M, Verdonck S, Meers K, Loossens T, Tuerlinckx F (2018) Prepaid
  parameter estimation without likelihoods.
\newblock {\em arXiv preprint arXiv:1812.09799}.

\bibitem{raynal2018abc}
Raynal L, et~al. (2018) Abc random forests for bayesian parameter inference.
\newblock {\em Bioinformatics} 35(10):1720--1728.

\bibitem{jiang2017learning}
Jiang B, Wu Ty, Zheng C, Wong WH (2017) Learning summary statistic for
  approximate bayesian computation via deep neural network.
\newblock {\em Statistica Sinica} pp. 1595--1618.

\bibitem{papamakarios2016fast}
Papamakarios G, Murray I (2016) Fast $\varepsilon$-free inference of simulation
  models with bayesian conditional density estimation in {\em Advances in
  Neural Information Processing Systems}.
\newblock pp. 1028--1036.

\bibitem{ardizzone2018analyzing}
Ardizzone L, et~al. (2018) Analyzing inverse problems with invertible neural
  networks.
\newblock {\em arXiv preprint arXiv:1808.04730}.

\bibitem{kingma2018glow}
Kingma DP, Dhariwal P (2018) Glow: Generative flow with invertible 1x1
  convolutions in {\em Advances in Neural Information Processing Systems}.
\newblock pp. 10215--10224.

\bibitem{grover2018flow}
Grover A, Dhar M, Ermon S (2018) Flow-gan: Combining maximum likelihood and
  adversarial learning in generative models in {\em Thirty-Second AAAI
  Conference on Artificial Intelligence}.

\bibitem{dinh2016density}
Dinh L, Sohl-Dickstein J, Bengio S (2016) Density estimation using real nvp.
\newblock {\em arXiv preprint arXiv:1605.08803}.

\bibitem{bloem2019probabilistic}
Bloem-Reddy B, Teh YW (2019) Probabilistic symmetry and invariant neural
  networks.
\newblock {\em arXiv preprint arXiv:1901.06082}.

\bibitem{goodfellow2016deep}
Goodfellow I, Bengio Y, Courville A (2016) {\em Deep learning}.
\newblock (MIT press).

\bibitem{kendall2017uncertainties}
Kendall A, Gal Y (2017) What uncertainties do we need in bayesian deep learning
  for computer vision? in {\em Advances in neural information processing
  systems}.
\newblock pp. 5574--5584.

\bibitem{gelman2013bayesian}
Gelman A, et~al. (2013) {\em Bayesian data analysis}.
\newblock (Chapman and Hall/CRC).

\bibitem{abadi2016tensorflow}
Abadi M, et~al. (2016) Tensorflow: A system for large-scale machine learning in
  {\em 12th $\{$USENIX$\}$ Symposium on Operating Systems Design and
  Implementation ($\{$OSDI$\}$ 16)}.
\newblock pp. 265--283.

\bibitem{kingma2014auto}
Kingma DP, Welling M (2014) Auto-encoding variational bayes.
\newblock {\em stat} 1050:1.

\end{thebibliography}
